{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e56e156e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import zipfile\n",
    "import os\n",
    "import matplotlib\n",
    "import dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c1a7306",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detector = dlib.get_frontal_face_detector()\n",
    "points_detector = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3490bf72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68 points[(365, 369), (366, 394), (370, 418), (375, 441), (383, 464), (396, 485), (413, 505), (431, 519), (451, 525), (474, 522), (496, 510), (516, 493), (532, 474), (543, 450), (549, 425), (554, 398), (557, 374), (377, 344), (387, 330), (403, 325), (421, 327), (436, 335), (472, 335), (490, 328), (509, 328), (528, 334), (538, 350), (452, 355), (451, 373), (450, 390), (448, 409), (430, 418), (440, 422), (450, 425), (460, 422), (470, 419), (396, 359), (406, 351), (419, 352), (430, 362), (418, 364), (405, 363), (479, 364), (490, 355), (504, 355), (515, 362), (505, 367), (491, 367), (413, 446), (425, 440), (439, 439), (449, 441), (460, 440), (476, 443), (493, 449), (477, 471), (461, 478), (449, 479), (438, 476), (424, 465), (419, 447), (439, 445), (449, 447), (460, 446), (488, 450), (461, 464), (449, 465), (439, 463)]\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread('0.jpg')\n",
    "face_detection = face_detector(image, 1)\n",
    "for face in face_detection:\n",
    "  points = points_detector(image, face)\n",
    "  for point in points.parts():\n",
    "    cv2.circle(image, (point.x, point.y), 2, (0,255,0), 1)\n",
    "\n",
    "  print(len(points.parts()), points.parts())\n",
    "\n",
    "  l, t, r, b = face.left(), face.top(), face.right(), face.bottom()\n",
    "  cv2.rectangle(image, (l, t), (r, b), (0,255,255), 2)\n",
    "cv2.imshow(\"AI\",image)\n",
    "cv2.waitKey(5000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15dccbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'archive.zip'\n",
    "zip_object = zipfile.ZipFile(file = path, mode = 'r')\n",
    "zip_object.extractall('./')\n",
    "zip_object.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189d8b16",
   "metadata": {},
   "source": [
    "## Detecting facial descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce091267",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_descriptor_extractor = dlib.face_recognition_model_v1('dlib_face_recognition_resnet_model_v1.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f8054ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = '9.jpg'\n",
    "image = Image.open(test_image).convert('L')\n",
    "image_np = np.array(image, 'uint8')\n",
    "image_np = cv2.cvtColor(image_np, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "face_detection = face_detector(image_np, 1)\n",
    "for face in face_detection:\n",
    "  l, t, r, b = face.left(), face.top(), face.right(), face.bottom()\n",
    "  cv2.rectangle(image_np, (l, t), (r, b), (255,0,255), 2)\n",
    "\n",
    "  points = points_detector(image_np, face)\n",
    "  for point in points.parts():\n",
    "    cv2.circle(image_np, (point.x, point.y), 2, (0,255,0), 1)\n",
    "\n",
    "  face_descriptor = face_descriptor_extractor.compute_face_descriptor(image_np, points)\n",
    "  \n",
    "  face_descriptor = [f for f in face_descriptor]\n",
    "  \n",
    "  face_descriptor = np.asarray(face_descriptor, dtype = np.float64)\n",
    " \n",
    "  face_descriptor = face_descriptor[np.newaxis, :]\n",
    "  \n",
    "\n",
    "cv2.imshow(\"AI\",image_np)\n",
    "cv2.waitKey(2000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6834b563",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_descriptor(face, image_np, face_descriptors):\n",
    "  l, t, r, b = face.left(), face.top(), face.right(), face.bottom()\n",
    "  cv2.rectangle(image_np, (l, t), (r, b), (0, 255, 0), 2)\n",
    "\n",
    "  points = points_detector(image_np, face)\n",
    "  for point in points.parts():\n",
    "    cv2.circle(image_np, (point.x, point.y), 2, (0, 255, 0), 1)\n",
    "\n",
    "  face_descriptor = face_descriptor_extractor.compute_face_descriptor(image_np, points)\n",
    "  face_descriptor = [f for f in face_descriptor]\n",
    "  face_descriptor = np.asarray(face_descriptor, dtype=np.float64)\n",
    "  face_descriptor = face_descriptor[np.newaxis, :]\n",
    "\n",
    "  if face_descriptors is None:\n",
    "    face_descriptors = face_descriptor\n",
    "  else:\n",
    "    face_descriptors = np.concatenate((face_descriptors, face_descriptor), axis = 0)\n",
    "\n",
    "  return image_np, face_descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1c5102",
   "metadata": {},
   "source": [
    "## Loading the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75519e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training(path_dataset):\n",
    "  index = {}\n",
    "  idx = 0\n",
    "  face_descriptors = None\n",
    "\n",
    "  paths = [os.path.join(path_dataset, f) for f in os.listdir(path_dataset)]\n",
    "\n",
    "  for path in paths:\n",
    "    #print(path)\n",
    "    image = Image.open(path).convert('L')\n",
    "    image_np = np.array(image, 'uint8')\n",
    "    image_np = cv2.cvtColor(image_np, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    face_detection = face_detector(image_np, 1)\n",
    "    for face in face_detection:\n",
    "      image_np, face_descriptors = extract_descriptor(face, image_np, face_descriptors)\n",
    "      index[idx] = path\n",
    "      idx += 1\n",
    "    #cv2.imshow(\"TEST\",image_np)\n",
    "    #cv2.waitKey(2000)\n",
    "    #cv2.destroyAllWindows()\n",
    "  return face_descriptors, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76134e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_descriptors, index = load_training('archive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c35b30f",
   "metadata": {},
   "source": [
    "## Recognizing Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ace3577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_images(path_dataset, face_descriptors, index, threshold=0.5):\n",
    "  predictions = []\n",
    "   \n",
    "  expected_outputs = []\n",
    "  paths = [os.path.join(path_dataset, f) for f in os.listdir(path_dataset)]\n",
    "  for path in paths:\n",
    "    image = Image.open(path).convert('RGB')\n",
    "    image_np = np.array(image, 'uint8')\n",
    "    (h, w) = image_np.shape[:2]\n",
    "    face_detection = face_detector(image_np, 1)\n",
    "    for face in face_detection:\n",
    "      points = points_detector(image_np, face)\n",
    "      face_descriptor = face_descriptor_extractor.compute_face_descriptor(image_np, points)\n",
    "      face_descriptor = [f for f in face_descriptor]\n",
    "      face_descriptor = np.asarray(face_descriptor, dtype=np.float64)\n",
    "      face_descriptor = face_descriptor[np.newaxis, :]\n",
    "\n",
    "      distances = np.linalg.norm(face_descriptor - face_descriptors, axis = 1)\n",
    "      min_index = np.argmin(distances)\n",
    "      min_distance = distances[min_index]\n",
    "      if min_distance <= threshold:\n",
    "        name_pred = os.path.split(index[min_index])[1].split('.')[0].replace('subject', '')\n",
    "      else:\n",
    "        name_pred = -1 # not identified\n",
    "\n",
    "      name_real = os.path.split(path)[1].split('.')[0].replace('subject', '')\n",
    "\n",
    "      predictions.append(name_pred)\n",
    "      expected_outputs.append(name_real)\n",
    "\n",
    "      cv2.putText(image_np, 'Pred: ' + str(name_pred), (10,30), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,255,255))\n",
    "      cv2.putText(image_np, 'Exp: ' + str(name_real), (10,50), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,255,0))\n",
    "      cv2.putText(image_np, str(min_distance), (10,h - 30), cv2.FONT_HERSHEY_COMPLEX_SMALL, 0.6, (0,0,255))\n",
    "      \n",
    "        \n",
    "    cv2.imshow(\"test\",image_np)\n",
    "    cv2.waitKey(3000)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "  predictions = np.array(predictions)\n",
    "  expected_outputs = np.array(expected_outputs)\n",
    "\n",
    "  return predictions, expected_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee4acf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, expected_outputs = predict_images('TEST_MODEL', face_descriptors, index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff6b249",
   "metadata": {},
   "source": [
    "## Saving Descriptors for future use ( Python Pickle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce514c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "np.save('face_descriptors.npy', face_descriptors)\n",
    "with open('index_faces.pickle', 'wb') as f:\n",
    "  pickle.dump(index, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a71c4417",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.load('index_faces.pickle', allow_pickle = True)\n",
    "face_descriptors = np.load('face_descriptors.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba9fdd7",
   "metadata": {},
   "source": [
    "## Display recognition above bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db1d47cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a08b88a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [os.path.join('archive', f) for f in os.listdir('archive') if f.endswith('.jpg')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6ac1c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_faces(image, list_encodings, list_names, tolerance = 0.6):\n",
    "  img_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "  face_locations = face_recognition.face_locations(img_rgb)\n",
    "  face_encodings = face_recognition.face_encodings(img_rgb, face_locations)\n",
    "  face_names = []\n",
    "  conf_values = []\n",
    "  for encoding in face_encodings:\n",
    "    matches = face_recognition.compare_faces(list_encodings, encoding, tolerance = tolerance)\n",
    "    name = 'Not identified'\n",
    "    face_distances = face_recognition.face_distance(list_encodings, encoding)\n",
    "    best_match_index = np.argmin(face_distances)\n",
    "    if matches[best_match_index]:\n",
    "      name = list_names[best_match_index]\n",
    "    face_names.append(name)\n",
    "    conf_values.append(face_distances[best_match_index])\n",
    "  face_locations = np.array(face_locations)\n",
    "  return face_locations.astype(int), face_names, conf_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07c32b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encodings(paths):\n",
    "  print('{} images found'.format(len(paths)))\n",
    "  list_encodings = []\n",
    "  list_names = []\n",
    "  for img_path in paths:\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    basename = os.path.basename(img_path)\n",
    "    #print(basename)\n",
    "    (name, ext) = os.path.splitext(basename)\n",
    "    #print(name, ext)\n",
    "    face_roi = face_recognition.face_locations(img, model = 'cnn') # hog\n",
    "    face_encoding = face_recognition.face_encodings(img, face_roi)[0]\n",
    "    if len(face_encoding) > 0:\n",
    "      list_encodings.append(face_encoding)\n",
    "      list_names.append(name)\n",
    "    else:\n",
    "      print('Could not detect the face from image {}'.format(img_path))\n",
    "  return list_encodings, list_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d0bc4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 images found\n"
     ]
    }
   ],
   "source": [
    "list_encodings, list_names = get_encodings(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5aaca9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('listEncodings.pickle','wb') as f:\n",
    "    #pickle.dump(list_encodings,f)\n",
    "\n",
    "with open('listNames.pickle','wb') as f:\n",
    "    pickle.dump(list_names,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90123e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfc7a0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_encodings = np.load('listEncodings.pickle', allow_pickle = True)\n",
    "list_names = np.load('listNames.pickle', allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e44f155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9aa7b167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_recognition(test_image, list_encodings, list_names, max_width=700, tolerance=0.6):\n",
    "  face_locations, face_names, conf_values = recognize_faces(test_image, list_encodings, list_names, tolerance)\n",
    "\n",
    "  for face_loc, name, conf in zip(face_locations, face_names, conf_values):\n",
    "    y1, x2, y2, x1 = face_loc[0], face_loc[1], face_loc[2], face_loc[3]\n",
    "\n",
    "    cv2.putText(test_image, name,(x1, y1 - 10), cv2.FONT_HERSHEY_DUPLEX, 0.5, (0,255,0), 1)\n",
    "    cv2.rectangle(test_image, (x1, y1), (x2, y2), (0,255,0), 3)\n",
    "    print(conf)\n",
    "\n",
    "  if (test_image.shape[1] > max_width):\n",
    "    test_image = imutils.resize(test_image, width=max_width)\n",
    "  cv2.imshow(\"AI\",test_image)\n",
    "  cv2.waitKey(10000)  \n",
    "  cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d3ad047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7948475879377213\n"
     ]
    }
   ],
   "source": [
    "test_image = cv2.imread('0.jpg')\n",
    "show_recognition(test_image, list_encodings, list_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
